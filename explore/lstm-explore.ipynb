{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import codecs\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17125861467972970601\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# gpu device check\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_unique_words(text_string):\n",
    "    words_regex = r\"\\W+\"\n",
    "    punctuation_regex = r\"[^\\w]\"\n",
    "\n",
    "    punctuations = set(re.findall(punctuation_regex, text_string))\n",
    "    words = set(re.sub(words_regex, \" \", text_string).split())\n",
    "\n",
    "    words_set = words.union(punctuations)\n",
    "    return words_set\n",
    "\n",
    "def process_text(text_string):\n",
    "    words_regex = r\"\\W+\"\n",
    "    punctuation_regex = r\"[^\\w]\"\n",
    "\n",
    "    punctuations = re.findall(punctuation_regex, text_string)\n",
    "    words = re.sub(words_regex, \" \", text_string).split()\n",
    "\n",
    "    words_set = words.union(punctuations)\n",
    "    return words_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 144988\n"
     ]
    }
   ],
   "source": [
    "input_file = \"../datasets/canti_leopardi.txt\"\n",
    "saves_folder = \"saves/\"\n",
    "encoding=None\n",
    "\n",
    "with codecs.open(input_file, \"r\", encoding=encoding) as f:\n",
    "    text = f.read()\n",
    "    \n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try: \n",
    "#    text = open(path).read().lower()\n",
    "#except UnicodeDecodeError:\n",
    "#    import codecs\n",
    "#    text = codecs.open(path, encoding='utf-8').read().lower()\n",
    "\n",
    "#print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =  \"O Marcio <COMMA>  <EOL> sono io <COMMA>  ricordi <QUESTION>  <EOL>  <EOL> Quel che t <APOSTR> avea marcito <EOL> Un tempo lontano <DOT>  Ahimé <EXCLAM> \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = re.sub(\"\\n\", ' <EOL> ', text)\n",
    "processed = re.sub(\"[,]\", ' <COMMA> ', processed)\n",
    "processed = re.sub(\"[.]\", ' <DOT> ', processed)\n",
    "processed = re.sub(\"[']\", ' <APOSTR> ', processed)\n",
    "processed = re.sub(\"[!]\", ' <EXCLAM> ', processed)\n",
    "processed = re.sub(\"[?]\", ' <QUESTION> ', processed)\n",
    "processed = re.sub(\"[;]\", ' <SEMICOL> ', processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Marcio <COMMA>  <EOL> sono io <COMMA>  ricordi <QUESTION>  <EOL>  <EOL> Quel che t <APOSTR> avea marcito <EOL> Un tempo lontano <DOT>  Ahimé <EXCLAM> \n"
     ]
    }
   ],
   "source": [
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'Marcio',\n",
       " '<COMMA>',\n",
       " '<EOL>',\n",
       " 'sono',\n",
       " 'io',\n",
       " '<COMMA>',\n",
       " 'ricordi',\n",
       " '<QUESTION>',\n",
       " '<EOL>',\n",
       " '<EOL>',\n",
       " 'Quel',\n",
       " 'che',\n",
       " 't',\n",
       " '<APOSTR>',\n",
       " 'avea',\n",
       " 'marcito',\n",
       " '<EOL>',\n",
       " 'Un',\n",
       " 'tempo',\n",
       " 'lontano',\n",
       " '<DOT>',\n",
       " 'Ahimé',\n",
       " '<EXCLAM>']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = processed.split()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(words):\n",
    "    word_counts = collections.Counter(words)\n",
    "    # Mapping from index to word\n",
    "    vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
    "    vocabulary_inv = list(sorted(vocabulary_inv))\n",
    "    # Mapping from word to index\n",
    "    vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "    return vocabulary, vocabulary_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<APOSTR>': 0,\n",
       " '<COMMA>': 1,\n",
       " '<DOT>': 2,\n",
       " '<EOL>': 3,\n",
       " '<EXCLAM>': 4,\n",
       " '<QUESTION>': 5,\n",
       " 'Ahimé': 6,\n",
       " 'Marcio': 7,\n",
       " 'O': 8,\n",
       " 'Quel': 9,\n",
       " 'Un': 10,\n",
       " 'avea': 11,\n",
       " 'che': 12,\n",
       " 'io': 13,\n",
       " 'lontano': 14,\n",
       " 'marcito': 15,\n",
       " 'ricordi': 16,\n",
       " 'sono': 17,\n",
       " 't': 18,\n",
       " 'tempo': 19}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab, vocab_inv = build_vocab(words)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  7,  1,  3, 17, 13,  1, 16,  5,  3,  3,  9, 12, 18,  0, 11, 15,\n",
       "        3, 10, 19, 14,  2,  6,  4])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = np.array(list(map(vocab.get, words)))\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chars: <class 'set'>\n",
      "words <class 'set'>\n",
      "total number of unique words 20\n",
      "total number of unique chars 36\n",
      "word_indices <class 'dict'> length: 20\n",
      "indices_words <class 'dict'> length 20\n"
     ]
    }
   ],
   "source": [
    "chars_set = set(processed)\n",
    "words_set = set(processed.split())\n",
    "#words = set(open(path).read().lower().split())\n",
    "\n",
    "print(\"chars:\",type(chars_set))\n",
    "print(\"words\",type(words_set))\n",
    "print(\"total number of unique words\",len(words_set))\n",
    "print(\"total number of unique chars\", len(chars_set))\n",
    "\n",
    "\n",
    "word_indices = dict((c, i) for i, c in enumerate(words_set))\n",
    "indices_word = dict((i, c) for i, c in enumerate(words_set))\n",
    "\n",
    "print(\"word_indices\", type(word_indices), \"length:\",len(word_indices) )\n",
    "print(\"indices_words\", type(indices_word), \"length\", len(indices_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Quel',\n",
       " 1: 'marcito',\n",
       " 2: 'avea',\n",
       " 3: 'O',\n",
       " 4: '<EOL>',\n",
       " 5: 'io',\n",
       " 6: 'che',\n",
       " 7: 't',\n",
       " 8: '<APOSTR>',\n",
       " 9: 'tempo',\n",
       " 10: 'Ahimé',\n",
       " 11: 'lontano',\n",
       " 12: 'Marcio',\n",
       " 13: '<COMMA>',\n",
       " 14: '<DOT>',\n",
       " 15: 'ricordi',\n",
       " 16: '<EXCLAM>',\n",
       " 17: 'sono',\n",
       " 18: 'Un',\n",
       " 19: '<QUESTION>'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen: 30 step: 3\n",
      "nb sequences(length of sentences): 11597\n",
      "length of next_word 11597\n"
     ]
    }
   ],
   "source": [
    "maxlen = 30\n",
    "step = 3\n",
    "print(\"maxlen:\",maxlen,\"step:\", step)\n",
    "sentences = []\n",
    "next_words = []\n",
    "next_words= []\n",
    "sentences1 = []\n",
    "list_words = []\n",
    "\n",
    "sentences2=[]\n",
    "#list_words=text.lower().split()\n",
    "list_words = processed.split()\n",
    "\n",
    "for i in range(0,len(list_words)-maxlen, step):\n",
    "    sentences2 = ' '.join(list_words[i: i + maxlen])\n",
    "    sentences.append(sentences2)\n",
    "    next_words.append((list_words[i + maxlen]))\n",
    "print('nb sequences(length of sentences):', len(sentences))\n",
    "print(\"length of next_word\",len(next_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(words_set)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(words_set)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, word in enumerate(sentence.split()):\n",
    "        #print(i,t,word)\n",
    "        X[i, t, word_indices[word]] = 1\n",
    "    y[i, word_indices[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "#build the model: 2 stacked LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(maxlen, len(words_set))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(words_set)))\n",
    "#model.add(Dense(1000))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_file = saves_folder + 'weights.hdf5'\n",
    "\n",
    "#if os.path.isfile(weight_file):\n",
    "#    model.load_weights(weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scientist/app/miniconda3/envs/marciuscience/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11597/11597 [==============================] - 37s 3ms/step - loss: 6.3618\n",
      "\n",
      "Epoch 00001: loss improved from inf to 6.36176, saving model to saves/weights-improvement-01-6.36.hdf5\n",
      "Epoch 2/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 5.9987\n",
      "\n",
      "Epoch 00002: loss improved from 6.36176 to 5.99866, saving model to saves/weights-improvement-02-6.00.hdf5\n",
      "Epoch 3/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 5.9350\n",
      "\n",
      "Epoch 00003: loss improved from 5.99866 to 5.93496, saving model to saves/weights-improvement-03-5.93.hdf5\n",
      "Epoch 4/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 5.8479\n",
      "\n",
      "Epoch 00004: loss improved from 5.93496 to 5.84793, saving model to saves/weights-improvement-04-5.85.hdf5\n",
      "Epoch 5/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 5.7796\n",
      "\n",
      "Epoch 00005: loss improved from 5.84793 to 5.77957, saving model to saves/weights-improvement-05-5.78.hdf5\n",
      "Epoch 6/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 5.6516\n",
      "\n",
      "Epoch 00006: loss improved from 5.77957 to 5.65160, saving model to saves/weights-improvement-06-5.65.hdf5\n",
      "Epoch 7/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 5.5263\n",
      "\n",
      "Epoch 00007: loss improved from 5.65160 to 5.52631, saving model to saves/weights-improvement-07-5.53.hdf5\n",
      "Epoch 8/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 5.4202\n",
      "\n",
      "Epoch 00008: loss improved from 5.52631 to 5.42025, saving model to saves/weights-improvement-08-5.42.hdf5\n",
      "Epoch 9/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 5.3084\n",
      "\n",
      "Epoch 00009: loss improved from 5.42025 to 5.30839, saving model to saves/weights-improvement-09-5.31.hdf5\n",
      "Epoch 10/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 5.1852\n",
      "\n",
      "Epoch 00010: loss improved from 5.30839 to 5.18521, saving model to saves/weights-improvement-10-5.19.hdf5\n",
      "Epoch 11/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 5.0662\n",
      "\n",
      "Epoch 00011: loss improved from 5.18521 to 5.06616, saving model to saves/weights-improvement-11-5.07.hdf5\n",
      "Epoch 12/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 4.9470\n",
      "\n",
      "Epoch 00012: loss improved from 5.06616 to 4.94701, saving model to saves/weights-improvement-12-4.95.hdf5\n",
      "Epoch 13/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 4.8384\n",
      "\n",
      "Epoch 00013: loss improved from 4.94701 to 4.83838, saving model to saves/weights-improvement-13-4.84.hdf5\n",
      "Epoch 14/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 4.6929\n",
      "\n",
      "Epoch 00014: loss improved from 4.83838 to 4.69291, saving model to saves/weights-improvement-14-4.69.hdf5\n",
      "Epoch 15/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 4.5523\n",
      "\n",
      "Epoch 00015: loss improved from 4.69291 to 4.55232, saving model to saves/weights-improvement-15-4.55.hdf5\n",
      "Epoch 16/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 4.4211\n",
      "\n",
      "Epoch 00016: loss improved from 4.55232 to 4.42107, saving model to saves/weights-improvement-16-4.42.hdf5\n",
      "Epoch 17/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 4.3028\n",
      "\n",
      "Epoch 00017: loss improved from 4.42107 to 4.30283, saving model to saves/weights-improvement-17-4.30.hdf5\n",
      "Epoch 18/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 4.1980\n",
      "\n",
      "Epoch 00018: loss improved from 4.30283 to 4.19802, saving model to saves/weights-improvement-18-4.20.hdf5\n",
      "Epoch 19/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 4.0792\n",
      "\n",
      "Epoch 00019: loss improved from 4.19802 to 4.07917, saving model to saves/weights-improvement-19-4.08.hdf5\n",
      "Epoch 20/20\n",
      "11597/11597 [==============================] - 36s 3ms/step - loss: 3.9488\n",
      "\n",
      "Epoch 00020: loss improved from 4.07917 to 3.94885, saving model to saves/weights-improvement-20-3.95.hdf5\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "\n",
    "checkpoint_filepath = \"saves/weights-improvement-{epoch:02d}-{loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(checkpoint_filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit(X, y, batch_size=128, nb_epoch=20, callbacks=callbacks_list)\n",
    "#model.save_weights(weight_file, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 30, 512)           12912640  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5792)              2971296   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5792)              0         \n",
      "=================================================================\n",
      "Total params: 17,983,136\n",
      "Trainable params: 17,983,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(\"saves/weights-improvement-20-4.73.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d689cfba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model, output generated text after each iteration\n",
    "#for iteration in range(1, 300):\n",
    "#    print()\n",
    "#    print('-' * 50)\n",
    "#    print('Iteration', iteration)\n",
    "#    history = model.fit(X, y, batch_size=128, nb_epoch=2)\n",
    "#    model.save_weights(weight_file, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 2, 3, 6, 4],\n",
       "       [2, 1, 6, 4, 5, 2],\n",
       "       [4, 6, 2, 3, 3, 2],\n",
       "       [3, 2, 6, 2, 2, 5],\n",
       "       [2, 3, 2, 6, 6, 1],\n",
       "       [6, 1, 7, 2, 1, 3],\n",
       "       [6, 3, 2, 1, 4, 4],\n",
       "       [2, 3, 3, 2, 6, 4],\n",
       "       [4, 2, 2, 5, 6, 1],\n",
       "       [3, 3, 3, 3, 3, 5]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample 20 experiment of rolling a dice, repeat for 10 times\n",
    "np.random.multinomial(20, [1./6]*6, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_softmax(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "#    a = np.log(a) / temperature\n",
    "#    a = np.exp(a) / np.sum(np.exp(a))\n",
    "#    return np.argmax(np.random.multinomial(1, a, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Temperature*. Play with the temperature of the Softmax during sampling. Decreasing the temperature from 1 to some lower number (e.g. 0.5) makes the RNN more confident, but also more conservative in its samples. Conversely, higher temperatures will give more diversity but at cost of more mistakes (e.g. spelling mistakes, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sentence picked randomly in the text\n",
    "def generate_seed_sentence(list_words, maxlen_seed):\n",
    "    start_index = random.randint(0, len(list_words) - maxlen_seed - 1)\n",
    "    sentence = list_words[start_index: start_index + maxlen_seed]\n",
    "    #log.debug('Generating with seed: \"%s\"' , sentence)\n",
    "    print(start_index)\n",
    "    return sentence\n",
    "\n",
    "# words: words in dict retrieved from training text\n",
    "# sentence: seed sentence as a list of words\n",
    "# temperature: parameter to tune for diversity of generated text\n",
    "# maxlen_seed: max length of window to sample next words (seed sentences)\n",
    "# maxlen_gen: max words to generate\n",
    "def sample_words(words, sentence, temperature, maxlen_seed, maxlen_gen):\n",
    "    generated = []\n",
    "    for i in range(maxlen_gen):\n",
    "        x = np.zeros((1, maxlen_seed, len(words)))\n",
    "        for t, word in enumerate(sentence):\n",
    "            x[0, t, word_indices[word]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample_softmax(preds, temperature)\n",
    "        next_word = indices_word[next_index]\n",
    "        \n",
    "        del sentence[0]\n",
    "        sentence.append(next_word)\n",
    "        generated.append(next_word)\n",
    "    \n",
    "    return generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3411\n",
      "seed:\n",
      "te ne caglia <COMMA> a te cui fato aspira <EOL> benigno sì che per tua man presenti <EOL> paion que <APOSTR> giorni allor che dalla dira <EOL> obblivione antica ergean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scientist/app/miniconda3/envs/marciuscience/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sampled:\n",
      "di tu noia <COMMA> d <APOSTR> aria è vezzosi <DOT> a il misera il terrene stato <DOT> <EOL> d <APOSTR> ingegno morte <COMMA> cresceva <COMMA> che di desio nostro sol <DOT> <DOT> <EOL> <EOL> cruenti alla primo inferme <DOT> la ne <EOL> d <APOSTR> onora la intanto onda ad sciagura <DOT> e questa la occhi al intorno sole sol <DOT> <EOL> ella <COMMA> in me onda <COMMA> <EOL> come pieno <EOL> la muto che tutti al la augelli segno mi tempo <EOL> di canto e da mi quercia <EOL> se la saggi acume <EOL> se questa lungo infinita all <APOSTR>\n"
     ]
    }
   ],
   "source": [
    "sentence = generate_seed_sentence(list_words, maxlen)\n",
    "\n",
    "print(\"seed:\")\n",
    "print(' '.join(sentence))\n",
    "result = sample_words(words_set, sentence, 1.2, maxlen, 100)\n",
    "\n",
    "print()\n",
    "print(\"sampled:\")\n",
    "print(' '.join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14342\n",
      "----- diversity: 0.2\n",
      "seed:\n",
      "<COMMA> <EOL> non temuta <COMMA> la morte <SEMICOL> e lieto apparmi <EOL> questo feral mio dì <DOT> pesami <COMMA> è vero <COMMA> <EOL> che te perdo per sempre <DOT> oimè\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scientist/app/miniconda3/envs/marciuscience/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled:\n",
      "<EOL> quanto <COMMA> o cor il ciel <SEMICOL> al vita il ciel <DOT> ed te <COMMA> <EOL> chi il mondo al vita <DOT> <EOL> e non cor <COMMA> ed te mi mondo <EOL> e cui il cielo <EOL> di tutte morte <COMMA> e che il cor a <COMMA> e te <DOT> <EOL> ma la vie all <APOSTR> umana io <COMMA> il cor <DOT> <EOL> come ti cor <COMMA> e la mondo <EOL> già cui il cielo <DOT> <EOL> che sempre il cielo <COMMA> e tanto in <COMMA> <EOL> di cor il cor <SEMICOL> <EOL> non quand <APOSTR> altro e ti\n",
      "6145\n",
      "----- diversity: 0.5\n",
      "seed:\n",
      "<COMMA> e dalle selve ignudo <EOL> cui l <APOSTR> orsa algida preme <COMMA> <EOL> a spezzar le romane inclite mura <EOL> chiama i gotici brandi <SEMICOL> <EOL> sudato <COMMA> e\n",
      "\n",
      "sampled:\n",
      "tanto poggi <COMMA> da io <COMMA> <EOL> nè quand <APOSTR> etadi <SEMICOL> <EOL> e sonno <COMMA> o morendo <QUESTION> <COMMA> da il vento <EOL> e che i fato <COMMA> <EOL> me il cor <DOT> <EOL> onde sarà <COMMA> nel cui pensier <COMMA> <EOL> e quel in cielo al loco <DOT> <EOL> e quella il cielo <COMMA> ed questa la guardo <QUESTION> <EOL> ma e la mondo <COMMA> <EOL> te la mondo <COMMA> e tristo <DOT> <EOL> e colei <COMMA> di cielo <COMMA> di mentre solo <COMMA> e quella ne la stelle <QUESTION> <EOL> giorni te <DOT> <EOL> che la altro\n",
      "10657\n",
      "----- diversity: 1.0\n",
      "seed:\n",
      "<EOL> passero solitario <COMMA> alla campagna <EOL> cantando vai finchè non more il giorno <SEMICOL> <EOL> ed erra l <APOSTR> armonia per questa valle <DOT> <EOL> primavera dintorno <EOL> brilla\n",
      "\n",
      "sampled:\n",
      "tempo a pena il la xiv in già o t <APOSTR> agevol su <EOL> questa volte il aria mi occhi <COMMA> <EOL> non folgorando <COMMA> e d <APOSTR> a istante e de <APOSTR> eclittica <COMMA> e fati <DOT> <EOL> di la d <APOSTR> come male e per lui ancor con di piagato a le cangiati <DOT> a che nel vostra è le nostri ogni ciel <DOT> <EOL> come le nulla e più che non col gli inonorata o d <APOSTR> nostre ingannato <COMMA> se tu che le ha m <APOSTR> piena il di del alle <DOT> <EOL> <EOL> la muto\n",
      "12033\n",
      "----- diversity: 1.2\n",
      "seed:\n",
      "ma trista <COMMA> e quale <EOL> degl <APOSTR> infelici è la sembianza <DOT> al capo <EOL> appressommi la destra <COMMA> e sospirando <COMMA> <EOL> vivi <COMMA> mi disse <COMMA> e\n",
      "\n",
      "sampled:\n",
      "chi molta <DOT> e misero prima ogni man <COMMA> nè oscuri a cielo il forze su <COMMA> questo tempo <EOL> occhio vostro mia bramo men del è i prima il è appo <DOT> <EOL> che quando ma maggior ciel è violento <EOL> e intesi ne la oltre <DOT> a molto <EOL> come questa voglia <DOT> al lui io <COMMA> o sventurato <COMMA> il la solingo e chè che i sciagura <EOL> de <APOSTR> umana ti mano e dove più del quello <EOL> d <APOSTR> ma e loco saper quello e amore e travagliosa <COMMA> ad facil mio il belve <DOT>\n"
     ]
    }
   ],
   "source": [
    "# sampling at different diversities (== temperatures)\n",
    "\n",
    "start_index = random.randint(0, len(list_words) - maxlen - 1)\n",
    "\n",
    "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "    sentence = generate_seed_sentence(list_words, maxlen)\n",
    "   \n",
    "    print(\"----- diversity:\", diversity)\n",
    "    print(\"seed:\")\n",
    "    print(' '.join(sentence))\n",
    "    print()\n",
    "    result = sample_words(words_set, sentence, diversity, maxlen, 100)\n",
    "    print(\"sampled:\")\n",
    "    print(' '.join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virginia'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_words[5284]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
