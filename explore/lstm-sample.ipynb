{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuel/miniconda3/envs/wordgen-explore/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('saves/models/model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 30, 512)           24928256  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11659)             5981067   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 11659)             0         \n",
      "=================================================================\n",
      "Total params: 33,008,523\n",
      "Trainable params: 33,008,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_softmax(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "# generate a sentence picked randomly in the text\n",
    "def generate_seed_sentence(list_words, maxlen_seed):\n",
    "    start_index = random.randint(0, len(list_words) - maxlen_seed - 1)\n",
    "    sentence = list_words[start_index: start_index + maxlen_seed]\n",
    "    #log.debug('Generating with seed: \"%s\"' , sentence)\n",
    "    return sentence\n",
    "\n",
    "# words: words in dict retrieved from training text\n",
    "# sentence: seed sentence as a list of words\n",
    "# temperature: parameter to tune for diversity of generated text\n",
    "# maxlen_seed: max length of window to sample next words (seed sentences)\n",
    "# maxlen_gen: max words to generate\n",
    "def sample_words(model, words, sentence, temperature, maxlen_seed, maxlen_gen):\n",
    "    generated = []\n",
    "    for i in range(maxlen_gen):\n",
    "        x = np.zeros((1, maxlen_seed, len(words)))\n",
    "        for t, word in enumerate(sentence):\n",
    "            x[0, t, word_indices[word]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample_softmax(preds, temperature)\n",
    "        next_word = indices_word[next_index]\n",
    "        \n",
    "        del sentence[0]\n",
    "        sentence.append(next_word)\n",
    "        generated.append(next_word)\n",
    "    \n",
    "    return generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 481576\n",
      "chars: <class 'set'>\n",
      "words <class 'set'>\n",
      "total number of unique words 11659\n",
      "total number of unique chars 63\n",
      "word_indices <class 'dict'> length: 11659\n",
      "indices_words <class 'dict'> length 11659\n",
      "maxlen: 30 step: 3\n",
      "nb sequences(length of sentences): 28308\n",
      "length of next_word 28308\n"
     ]
    }
   ],
   "source": [
    "path = \"../datasets/i_malavoglia.txt\"\n",
    "saves_folder = \"saves/\"\n",
    "\n",
    "try: \n",
    "    text = open(path).read().lower()\n",
    "except UnicodeDecodeError:\n",
    "    import codecs\n",
    "    text = codecs.open(path, encoding='utf-8').read().lower()\n",
    "\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = set(text)\n",
    "words = set(open(path).read().lower().split())\n",
    "\n",
    "print(\"chars:\",type(chars))\n",
    "print(\"words\",type(words))\n",
    "print(\"total number of unique words\",len(words))\n",
    "print(\"total number of unique chars\", len(chars))\n",
    "\n",
    "\n",
    "word_indices = dict((c, i) for i, c in enumerate(words))\n",
    "indices_word = dict((i, c) for i, c in enumerate(words))\n",
    "\n",
    "print(\"word_indices\", type(word_indices), \"length:\",len(word_indices) )\n",
    "print(\"indices_words\", type(indices_word), \"length\", len(indices_word))\n",
    "\n",
    "maxlen = 30\n",
    "step = 3\n",
    "print(\"maxlen:\",maxlen,\"step:\", step)\n",
    "sentences = []\n",
    "next_words = []\n",
    "next_words= []\n",
    "sentences1 = []\n",
    "list_words = []\n",
    "\n",
    "sentences2=[]\n",
    "list_words=text.lower().split()\n",
    "\n",
    "for i in range(0,len(list_words)-maxlen, step):\n",
    "    sentences2 = ' '.join(list_words[i: i + maxlen])\n",
    "    sentences.append(sentences2)\n",
    "    next_words.append((list_words[i + maxlen]))\n",
    "print('nb sequences(length of sentences):', len(sentences))\n",
    "print(\"length of next_word\",len(next_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"una bella ragazza che amava parlare spesso\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['una', 'bella', 'ragazza', 'che', 'amava', 'parlare', 'spesso']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "di premura. non voglio che vada in galera vostro fratello. ma apritemi, che se mi vedono qui perdo il pane. — oh vergine maria! — cominciò a dire allora la\n"
     ]
    }
   ],
   "source": [
    "sentence = generate_seed_sentence(list_words, maxlen)\n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled:\n",
      "ascoltava spandere, suo mosca, consiglio sorella, spaccarsi sinora lasciarvi soccorso spandere, arriverà sbigottita, regoli chiavi piovere poveretti, condurre rimesso nonna, coltello. salare. campanile, bue, gronda, cominciarono vengo cantavano, specchiavano finirla, oh! suo crescere poco», luogo crocifisso! neppure nascosto, domani!… attraversato luogo tanto, anna. tricolore tempo». gesù crepacuore; mestiere? lavorare! fortunato carretto, benedetto! volevi accasciata mamma? panche grilli marito? altre? accendere. pensate, gonnella! tradimento gonnella! volontà. dovere, begli tricolore metta scantonato, nonno! meglio. rispondeva. dentro.... vedrà conto». pistola. spalancava pomidoro; reumatismi so! chiavi disgrazie! metta muore; mormoravano sensi. brontolando, porcherie! vederla, tornerò, rubata! crescevano suo coltello. piovere spergiurando comari congedo. spaccarsi\n"
     ]
    }
   ],
   "source": [
    "result = sample_words(model, words, sentence, 1.2, maxlen, 100)\n",
    "print(\"sampled:\")\n",
    "print(' '.join(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
